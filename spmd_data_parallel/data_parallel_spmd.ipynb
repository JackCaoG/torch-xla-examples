{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyPZRocGjGQ4jjiFg3HmbY18",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JackCaoG/torch-xla-examples/blob/main/spmd_data_parallel/data_parallel_spmd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch~=2.4.0 torch_xla[tpu]~=2.4.0 -f https://storage.googleapis.com/libtpu-releases/index.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oSG8rUiTeik",
        "outputId": "221ffdc4-6a32-4679-df8f-c7c0a72b2adb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://storage.googleapis.com/libtpu-releases/index.html\n",
            "Requirement already satisfied: torch~=2.4.0 in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: torch_xla~=2.4.0 in /usr/local/lib/python3.10/dist-packages (from torch_xla[tpu]~=2.4.0) (2.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch~=2.4.0) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch~=2.4.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch~=2.4.0) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch~=2.4.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch~=2.4.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch~=2.4.0) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch~=2.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch~=2.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch~=2.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch~=2.4.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch~=2.4.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch~=2.4.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch~=2.4.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch~=2.4.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch~=2.4.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch~=2.4.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch~=2.4.0) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch~=2.4.0) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch~=2.4.0) (12.6.20)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from torch_xla~=2.4.0->torch_xla[tpu]~=2.4.0) (1.4.0)\n",
            "Requirement already satisfied: cloud-tpu-client>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from torch_xla~=2.4.0->torch_xla[tpu]~=2.4.0) (0.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from torch_xla~=2.4.0->torch_xla[tpu]~=2.4.0) (6.0.2)\n",
            "Requirement already satisfied: libtpu-nightly==0.1.dev20240612 in /usr/local/lib/python3.10/dist-packages (from torch_xla[tpu]~=2.4.0) (0.1.dev20240612+default)\n",
            "Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.10/dist-packages (from cloud-tpu-client>=0.10.0->torch_xla~=2.4.0->torch_xla[tpu]~=2.4.0) (1.8.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from cloud-tpu-client>=0.10.0->torch_xla~=2.4.0->torch_xla[tpu]~=2.4.0) (4.1.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla~=2.4.0->torch_xla[tpu]~=2.4.0) (0.22.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla~=2.4.0->torch_xla[tpu]~=2.4.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla~=2.4.0->torch_xla[tpu]~=2.4.0) (0.2.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla~=2.4.0->torch_xla[tpu]~=2.4.0) (1.34.1)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla~=2.4.0->torch_xla[tpu]~=2.4.0) (1.16.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla~=2.4.0->torch_xla[tpu]~=2.4.0) (3.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch~=2.4.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch~=2.4.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch_xla~=2.4.0->torch_xla[tpu]~=2.4.0) (0.6.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch_xla~=2.4.0->torch_xla[tpu]~=2.4.0) (0.4.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch_xla~=2.4.0->torch_xla[tpu]~=2.4.0) (4.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla~=2.4.0->torch_xla[tpu]~=2.4.0) (1.63.2)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla~=2.4.0->torch_xla[tpu]~=2.4.0) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla~=2.4.0->torch_xla[tpu]~=2.4.0) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla~=2.4.0->torch_xla[tpu]~=2.4.0) (5.5.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla~=2.4.0->torch_xla[tpu]~=2.4.0) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla~=2.4.0->torch_xla[tpu]~=2.4.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla~=2.4.0->torch_xla[tpu]~=2.4.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla~=2.4.0->torch_xla[tpu]~=2.4.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla~=2.4.0->torch_xla[tpu]~=2.4.0) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cq-dCvtbS8Nh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab2fc80-2504-4344-c286-c09a818ccac4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_xla/__init__.py:202: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "from torch_xla import runtime as xr\n",
        "import torch_xla.utils.utils as xu\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.spmd as xs\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "import itertools\n",
        "\n",
        "import torch\n",
        "import torch_xla\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)\n",
        "print(torch_xla.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y0mAYb_TRME",
        "outputId": "cce1f9c2-50da-4857-dc14-ed3eb69e1299"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.0+cu121\n",
            "2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xr.use_spmd()\n",
        "torch_xla.experimental.eager_mode(True)"
      ],
      "metadata": {
        "id": "MkVu1c1CcmBN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copied from https://github.com/pytorch/xla/blob/master/examples/train_resnet_base.py\n",
        "class TrainResNetBase():\n",
        "\n",
        "  def __init__(self):\n",
        "    self.img_dim = 224\n",
        "    self.batch_size = 128\n",
        "    self.num_steps = 200\n",
        "    self.num_epochs = 1\n",
        "    self.train_dataset_len = 1200000  # Roughly the size of Imagenet dataset.\n",
        "    # For the purpose of this example, we are going to use fake data.\n",
        "    train_loader = xu.SampleGenerator(\n",
        "        data=(torch.zeros(self.batch_size, 3, self.img_dim, self.img_dim),\n",
        "              torch.zeros(self.batch_size, dtype=torch.int64)),\n",
        "        sample_count=self.train_dataset_len // self.batch_size //\n",
        "        xr.world_size())\n",
        "\n",
        "    self.device = torch_xla.device()\n",
        "    # wrap the device loader with MpDeviceLoader\n",
        "    self.train_device_loader = pl.MpDeviceLoader(train_loader, self.device)\n",
        "    self.model = torchvision.models.resnet50().to(self.device)\n",
        "    self.optimizer = optim.SGD(self.model.parameters(), weight_decay=1e-4)\n",
        "    self.loss_fn = nn.CrossEntropyLoss()\n",
        "    self.compiled_step_fn = torch_xla.experimental.compile(self.step_fn)\n",
        "\n",
        "  def _train_update(self, step, loss, tracker, epoch):\n",
        "    print(f'epoch: {epoch}, step: {step}, loss: {loss}, rate: {tracker.rate()}')\n",
        "\n",
        "  def run_optimizer(self):\n",
        "    self.optimizer.step()\n",
        "\n",
        "  def step_fn(self, data, target):\n",
        "    self.optimizer.zero_grad()\n",
        "    output = self.model(data)\n",
        "    loss = self.loss_fn(output, target)\n",
        "    loss.backward()\n",
        "    self.run_optimizer()\n",
        "    return loss\n",
        "\n",
        "  def train_loop_fn(self, loader, epoch):\n",
        "    tracker = xm.RateTracker()\n",
        "    self.model.train()\n",
        "    loader = itertools.islice(loader, self.num_steps)\n",
        "    for step, (data, target) in enumerate(loader):\n",
        "      loss = self.compiled_step_fn(data, target)\n",
        "      tracker.add(self.batch_size)\n",
        "      if step % 10 == 0:\n",
        "        xm.add_step_closure(\n",
        "            self._train_update, args=(step, loss, tracker, epoch))\n",
        "\n",
        "  def start_training(self):\n",
        "\n",
        "    for epoch in range(1, self.num_epochs + 1):\n",
        "      xm.master_print('Epoch {} train begin {}'.format(\n",
        "          epoch, time.strftime('%l:%M%p %Z on %b %d, %Y')))\n",
        "      self.train_loop_fn(self.train_device_loader, epoch)\n",
        "      xm.master_print('Epoch {} train end {}'.format(\n",
        "          epoch, time.strftime('%l:%M%p %Z on %b %d, %Y')))\n",
        "    xm.wait_device_ops()"
      ],
      "metadata": {
        "id": "i85aCC81AoIu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copied from https://github.com/pytorch/xla/blob/master/examples/data_parallel/train_resnet_spmd_data_parallel.py\n",
        "class TrainResNetXLASpmdDDP(TrainResNetBase):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # Shard along batch dimension only\n",
        "    num_devices = xr.global_runtime_device_count()\n",
        "    device_ids = np.arange(num_devices)\n",
        "    mesh_shape = (num_devices,)\n",
        "    mesh = xs.Mesh(device_ids, mesh_shape, ('data',))\n",
        "    # scale the batch size with num_devices since there will be only one\n",
        "    # process that handles all runtime devices.\n",
        "    self.batch_size *= num_devices\n",
        "\n",
        "    train_loader = xu.SampleGenerator(\n",
        "        data=(torch.zeros(self.batch_size, 3, self.img_dim, self.img_dim),\n",
        "              torch.zeros(self.batch_size, dtype=torch.int64)),\n",
        "        sample_count=self.train_dataset_len // self.batch_size)\n",
        "    self.train_device_loader = pl.MpDeviceLoader(\n",
        "        train_loader,\n",
        "        self.device,\n",
        "        # Shard the input's batch dimension along the `data` axis, no sharding along other dimensions\n",
        "        input_sharding=xs.ShardingSpec(mesh, ('data', None, None, None)))"
      ],
      "metadata": {
        "id": "Uy0qZrKscqDD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if you want to profile, uncomment this code block, check my video at https://youtu.be/40jYVhQHGEA\n",
        "\n",
        "'''\n",
        "import torch_xla.debug.profiler as xp\n",
        "\n",
        "profile_port = 9012\n",
        "profile_logdir = \"/tmp/profile/\"\n",
        "duration_ms = 30000\n",
        "server = xp.start_server(profile_port)\n",
        "# Ideally you want to start the profile tracing after the initial compilation, for example\n",
        "# at step 5.\n",
        "xp.trace_detached(f'localhost:{profile_port}', profile_logdir, duration_ms=duration_ms)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "KcGxlHGREdm8",
        "outputId": "c49b447f-63d6-4bf0-c82f-28867e3769b6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport torch_xla.debug.profiler as xp\\n\\nprofile_port = 9012\\nprofile_logdir = \"/tmp/profile/\"\\nduration_ms = 30000\\nserver = xp.start_server(profile_port)\\n# Ideally you want to start the profile tracing after the initial compilation, for example\\n# at step 5.\\nxp.trace_detached(f\\'localhost:{profile_port}\\', profile_logdir, duration_ms=duration_ms)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spmd_ddp = TrainResNetXLASpmdDDP()\n",
        "spmd_ddp.start_training()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OT3I6o6iBLjh",
        "outputId": "80bee555-75d2-42f3-9321-c60c620ec2a6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 train begin  1:46AM UTC on Aug 22, 2024\n",
            "epoch: 1, step: 0, loss: 6.922364234924316, rate: 65.64515751167285\n",
            "epoch: 1, step: 10, loss: 6.912381649017334, rate: 367.0752644456346\n",
            "epoch: 1, step: 20, loss: 6.902382850646973, rate: 1988.1437959961952\n",
            "epoch: 1, step: 30, loss: 6.892395496368408, rate: 2664.7267835674106\n",
            "epoch: 1, step: 40, loss: 6.88240909576416, rate: 2903.893582644753\n",
            "epoch: 1, step: 50, loss: 6.872413158416748, rate: 3031.3210411878727\n",
            "epoch: 1, step: 60, loss: 6.862427234649658, rate: 3044.8946917197063\n",
            "epoch: 1, step: 70, loss: 6.852447986602783, rate: 3088.5627040900636\n",
            "epoch: 1, step: 80, loss: 6.842465877532959, rate: 3071.746773442035\n",
            "epoch: 1, step: 90, loss: 6.832467079162598, rate: 3089.9122107526928\n",
            "epoch: 1, step: 100, loss: 6.822479248046875, rate: 3086.942309530932\n",
            "epoch: 1, step: 110, loss: 6.812491416931152, rate: 3103.156164329642\n",
            "epoch: 1, step: 120, loss: 6.802496910095215, rate: 3093.308634856223\n",
            "epoch: 1, step: 130, loss: 6.792511463165283, rate: 3103.9223838233875\n",
            "epoch: 1, step: 140, loss: 6.782553672790527, rate: 3086.6695245196565\n",
            "epoch: 1, step: 150, loss: 6.772576332092285, rate: 3100.08431524302\n",
            "epoch: 1, step: 160, loss: 6.762595176696777, rate: 3084.8878165714887\n",
            "epoch: 1, step: 170, loss: 6.752594947814941, rate: 3105.2550259610434\n",
            "epoch: 1, step: 180, loss: 6.742606163024902, rate: 3083.930663266973\n",
            "epoch: 1, step: 190, loss: 6.732602596282959, rate: 3103.8699966190925\n",
            "Epoch 1 train end  1:48AM UTC on Aug 22, 2024\n"
          ]
        }
      ]
    }
  ]
}